{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00165aaf10ca4e61a424e5960e8783d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7f7a65d1a8b4b5085a68cccbd5883ba",
              "IPY_MODEL_7c928bd97584499c928090ae581fafd2",
              "IPY_MODEL_af4b9600e9ea46158c6ccb44afcee88d"
            ],
            "layout": "IPY_MODEL_61844edc71d64f48885e06fee4692281"
          }
        },
        "b7f7a65d1a8b4b5085a68cccbd5883ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f19b2bd233794aa08a45b530a2e3acfe",
            "placeholder": "​",
            "style": "IPY_MODEL_79f0d827b98b43f28b0ac3eda81ab1fe",
            "value": "Downloading builder script: 100%"
          }
        },
        "7c928bd97584499c928090ae581fafd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_365f234f3c3d400b9d2d5770996db63c",
            "max": 6927,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cf4472bc8f2473ea175e0e5cb11f952",
            "value": 6927
          }
        },
        "af4b9600e9ea46158c6ccb44afcee88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d534d2dc8baa4940bde4925c65cd4509",
            "placeholder": "​",
            "style": "IPY_MODEL_9bdbf42fe0e044b4a0267abc3da86f53",
            "value": " 6.93k/6.93k [00:00&lt;00:00, 534kB/s]"
          }
        },
        "61844edc71d64f48885e06fee4692281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f19b2bd233794aa08a45b530a2e3acfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f0d827b98b43f28b0ac3eda81ab1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "365f234f3c3d400b9d2d5770996db63c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf4472bc8f2473ea175e0e5cb11f952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d534d2dc8baa4940bde4925c65cd4509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bdbf42fe0e044b4a0267abc3da86f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3be5b503515c4b7284ceb346946239e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0162cfd1cc384bb1ac5f7c2bac0ebff6",
              "IPY_MODEL_80bf333413c940fe945d53a7f610ddcb",
              "IPY_MODEL_0f1ebade3592408a95753eef148c0bb3"
            ],
            "layout": "IPY_MODEL_e91e9dc2fd8d497eae428cf1fbf56f92"
          }
        },
        "0162cfd1cc384bb1ac5f7c2bac0ebff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d95e46091b54589a0a5a046f5b063a5",
            "placeholder": "​",
            "style": "IPY_MODEL_4841487e7a3540859aefd4c3fc7553c7",
            "value": "Downloading data: 100%"
          }
        },
        "80bf333413c940fe945d53a7f610ddcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4038803d1954445ea8fc34cf9340c034",
            "max": 599344244,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_828e885b706e421696d8168a647c3c0a",
            "value": 599344244
          }
        },
        "0f1ebade3592408a95753eef148c0bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dedd7be6aa9b46e9a77df77bdb78f204",
            "placeholder": "​",
            "style": "IPY_MODEL_d0be7390e28a45fe9211803ec70e9b5c",
            "value": " 599M/599M [00:02&lt;00:00, 419MB/s]"
          }
        },
        "e91e9dc2fd8d497eae428cf1fbf56f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d95e46091b54589a0a5a046f5b063a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4841487e7a3540859aefd4c3fc7553c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4038803d1954445ea8fc34cf9340c034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828e885b706e421696d8168a647c3c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dedd7be6aa9b46e9a77df77bdb78f204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0be7390e28a45fe9211803ec70e9b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "214eec81a18948ed8fc2122afb9ce672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24646dc97371483eaed360ab3864be3f",
              "IPY_MODEL_a9216259974145d68b35d04413b488e2",
              "IPY_MODEL_9bee47a0ec814934a60eeed6b6939c3f"
            ],
            "layout": "IPY_MODEL_e3f4a9c475b9405c8e49e4d9006b303e"
          }
        },
        "24646dc97371483eaed360ab3864be3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0616659b8003437db7613ba240f178b2",
            "placeholder": "​",
            "style": "IPY_MODEL_4407cb1023fa4ccab6e14574b25bc3f6",
            "value": "Generating train split: 100%"
          }
        },
        "a9216259974145d68b35d04413b488e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3347fb8307457d9bbf825487afa7c1",
            "max": 1825077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3fa8b1ea6d14d43b85d833ffd08bf91",
            "value": 1825077
          }
        },
        "9bee47a0ec814934a60eeed6b6939c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894f44bd8ca94babb75667ee65800546",
            "placeholder": "​",
            "style": "IPY_MODEL_ca05ebc5132b46dfadef9464530adb40",
            "value": " 1825077/1825077 [00:09&lt;00:00, 214661.50 examples/s]"
          }
        },
        "e3f4a9c475b9405c8e49e4d9006b303e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0616659b8003437db7613ba240f178b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4407cb1023fa4ccab6e14574b25bc3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a3347fb8307457d9bbf825487afa7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3fa8b1ea6d14d43b85d833ffd08bf91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "894f44bd8ca94babb75667ee65800546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca05ebc5132b46dfadef9464530adb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d9b1e5cdea44766a004f73727d518eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96835771e5f249ada17a36518cb735df",
              "IPY_MODEL_6408abd78e1644cc8a99b12cf22912e2",
              "IPY_MODEL_1dd2e03048ad4ec69431e2e92974a9e8"
            ],
            "layout": "IPY_MODEL_7be2b9db25fb41dcb10d21a2d7face9b"
          }
        },
        "96835771e5f249ada17a36518cb735df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb7c30e9a48745c0811ccb1590ef83d7",
            "placeholder": "​",
            "style": "IPY_MODEL_de7d1dd6f23d4da6bef8a35466116d16",
            "value": "Downloading builder script: 100%"
          }
        },
        "6408abd78e1644cc8a99b12cf22912e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ff9b6e7b77418f8ddf58066c9efbba",
            "max": 6927,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cae8598cdf44a3db72403f7ceaca4e0",
            "value": 6927
          }
        },
        "1dd2e03048ad4ec69431e2e92974a9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b3bb079f1a41ae9c279e3abec0c760",
            "placeholder": "​",
            "style": "IPY_MODEL_f99f4baafd9c41f89720c216e6dc3365",
            "value": " 6.93k/6.93k [00:00&lt;00:00, 594kB/s]"
          }
        },
        "7be2b9db25fb41dcb10d21a2d7face9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7c30e9a48745c0811ccb1590ef83d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7d1dd6f23d4da6bef8a35466116d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76ff9b6e7b77418f8ddf58066c9efbba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cae8598cdf44a3db72403f7ceaca4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0b3bb079f1a41ae9c279e3abec0c760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99f4baafd9c41f89720c216e6dc3365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "# !pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnQjdciDnMm4",
        "outputId": "e9197481-003d-40f2-d556-3ebaee4dae5a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vot737IxnQ5D",
        "outputId": "e1a90874-70ac-46aa-f67b-ae3e8a511bc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Personal Transformer\n",
        "import spacy\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"ashwinradhe/dl_dataset\")\n",
        "small_train_dataset = raw_datasets['train'].select(range(100000))\n",
        "SRC_LANGUAGE = \"en\"\n",
        "TRG_LANGUAGE = \"fr\"\n",
        "tokenizer_en = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "tokenizer_fr= get_tokenizer('spacy', language='fr_core_news_sm')\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "def tokenize_and_build_vocab(data, tokenizer):\n",
        "    tokenized_data = [tokenizer(sentence) for sentence in data]\n",
        "    vocab = build_vocab_from_iterator(tokenized_data,min_freq=1, specials=special_symbols,special_first=True)\n",
        "    vocab.set_default_index(vocab['<unk>'])\n",
        "    return vocab, tokenized_data\n",
        "vocab_en, tokenized_data_en = tokenize_and_build_vocab(small_train_dataset['English Sentence'], tokenizer_en)\n",
        "vocab_fr, tokenized_data_fr = tokenize_and_build_vocab(small_train_dataset['French Sentence'], tokenizer_fr)\n",
        "def numericalize_and_pad(tokenized_data, vocab):\n",
        "    numericalized_data = [torch.tensor(vocab.lookup_indices(sentence)) for sentence in tokenized_data]\n",
        "    padded_data = pad_sequence(numericalized_data, batch_first=True, padding_value=vocab['<pad>'])\n",
        "    return padded_data\n",
        "padded_data_en = numericalize_and_pad(tokenized_data_en, vocab_en)\n",
        "padded_data_fr = numericalize_and_pad(tokenized_data_fr, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "3be5b503515c4b7284ceb346946239e8",
            "0162cfd1cc384bb1ac5f7c2bac0ebff6",
            "80bf333413c940fe945d53a7f610ddcb",
            "0f1ebade3592408a95753eef148c0bb3",
            "e91e9dc2fd8d497eae428cf1fbf56f92",
            "3d95e46091b54589a0a5a046f5b063a5",
            "4841487e7a3540859aefd4c3fc7553c7",
            "4038803d1954445ea8fc34cf9340c034",
            "828e885b706e421696d8168a647c3c0a",
            "dedd7be6aa9b46e9a77df77bdb78f204",
            "d0be7390e28a45fe9211803ec70e9b5c",
            "214eec81a18948ed8fc2122afb9ce672",
            "24646dc97371483eaed360ab3864be3f",
            "a9216259974145d68b35d04413b488e2",
            "9bee47a0ec814934a60eeed6b6939c3f",
            "e3f4a9c475b9405c8e49e4d9006b303e",
            "0616659b8003437db7613ba240f178b2",
            "4407cb1023fa4ccab6e14574b25bc3f6",
            "4a3347fb8307457d9bbf825487afa7c1",
            "b3fa8b1ea6d14d43b85d833ffd08bf91",
            "894f44bd8ca94babb75667ee65800546",
            "ca05ebc5132b46dfadef9464530adb40"
          ]
        },
        "id": "3HMsdc-enUWy",
        "outputId": "fb6400ec-cdee-41eb-e45a-bb1c386c504e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/599M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3be5b503515c4b7284ceb346946239e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1825077 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "214eec81a18948ed8fc2122afb9ce672"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "dataset = torch.utils.data.TensorDataset(padded_data_en, padded_data_fr)\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "-mJclkBEnatS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJt85FHSnB2C",
        "outputId": "b88e2219-23b2-4717-ec01-b8f2fb29050d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(-torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size: int):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, num_tokens_en, num_tokens_fr, embed_size, nhead, dim_feedforward, max_seq_length):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.src_tok_emb = TokenEmbedding(num_tokens_en, embed_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(num_tokens_fr, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, dropout=0.1, maxlen=max_seq_length)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=0.1)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=0.1)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=3)\n",
        "        self.generator = nn.Linear(embed_size, num_tokens_fr)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        return self.transformer_encoder(src_emb, src_key_padding_mask=src_mask)\n",
        "\n",
        "    def decode(self, tgt, memory, tgt_mask, tgt_key_padding_mask):\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt))\n",
        "        return self.transformer_decoder(tgt_emb, memory, tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n",
        "        memory = self.encode(src, src_padding_mask)\n",
        "        output = self.decode(tgt, memory, tgt_mask, tgt_padding_mask)\n",
        "        return self.generator(output)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = torch.triu(torch.ones(sz, sz, device=device)).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "model_sgd_n = TransformerModel(len(vocab_en), len(vocab_fr), embed_size=64, nhead=8, dim_feedforward=1024, max_seq_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Adam/absolute_positional_encoding/crossentropyloss/model_weights.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8mBopjEnwC1",
        "outputId": "4972aa66-4e74-49a3-ee54-9bb220dbe370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss = test_and_evaluate(model, test_dataloader, seq2seq_loss, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plAfrRwmompw",
        "outputId": "b970ae33-7358-4aea-ab06-30785eea476e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.08188700818458425}\n",
            "Test Loss: 3.3265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cel.load_state_dict(torch.load('/content/drive/MyDrive/Adam/absolute_positional_encoding/crossentropywithlabelsmoothning/model_cel_state_dict.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JfpofQ2qi9W",
        "outputId": "20b7fe92-f3a0-4bf6-dab1-d60d79d05598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_ls = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX,label_smoothing=0.1)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_cel.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_ls = test_and_evaluate(model_cel, test_dataloader, seq2seq_loss_ls, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySnE8JeopjU1",
        "outputId": "f171c3a9-821e-4fc9-d525-5c6ab72f3e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.07580169478000488}\n",
            "Test Loss: 4.8215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sc.load_state_dict(torch.load('/content/drive/MyDrive/Adam/absolute_positional_encoding/sparsecategoricalcrossentropy/model_weights_sc.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WER7oAMrPzI",
        "outputId": "b56aa2a8-b148-4848-a7ee-773548cd989c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_n = nn.NLLLoss(ignore_index=PAD_IDX)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_sc.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          logits = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_ls = test_and_evaluate(model_sc, test_dataloader, seq2seq_loss_n, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "4d9b1e5cdea44766a004f73727d518eb",
            "96835771e5f249ada17a36518cb735df",
            "6408abd78e1644cc8a99b12cf22912e2",
            "1dd2e03048ad4ec69431e2e92974a9e8",
            "7be2b9db25fb41dcb10d21a2d7face9b",
            "cb7c30e9a48745c0811ccb1590ef83d7",
            "de7d1dd6f23d4da6bef8a35466116d16",
            "76ff9b6e7b77418f8ddf58066c9efbba",
            "3cae8598cdf44a3db72403f7ceaca4e0",
            "f0b3bb079f1a41ae9c279e3abec0c760",
            "f99f4baafd9c41f89720c216e6dc3365"
          ]
        },
        "id": "Vydu_arcri4M",
        "outputId": "dc6d1380-1d44-424a-a389-a4c747a4375d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.93k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d9b1e5cdea44766a004f73727d518eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.12180915044027014}\n",
            "Test Loss: 3.4901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_adamw.load_state_dict(torch.load('/content/drive/MyDrive/Adamw/absolute_positional_encoding/crossentropyloss/model_metrics_adamw.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6KqA05PsA-D",
        "outputId": "2c7dd22b-4b2a-45d0-f050-8f137e34628e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_adamw = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_adamw.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                 # print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_adamw = test_and_evaluate(model_adamw, test_dataloader, seq2seq_loss_adamw, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKaQpbpiwJza",
        "outputId": "cac8e942-6aa2-4dcf-cb0e-854fb5badb86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.11332490852304318}\n",
            "Test Loss: 3.1401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_adamw_c.load_state_dict(torch.load('/content/drive/MyDrive/Adamw/absolute_positional_encoding/crossentropywithlabelsmoothning/model_state_adamw_c.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNGjifJrxG8e",
        "outputId": "1f7ac53b-c1d3-45e1-9e4b-2338b95fbe28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_adamw_ls = nn.CrossEntropyLoss(ignore_index=PAD_IDX,label_smoothing=0.5)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_adamw_c.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_adamw = test_and_evaluate(model_adamw_c, test_dataloader, seq2seq_loss_adamw_ls, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "00165aaf10ca4e61a424e5960e8783d9",
            "b7f7a65d1a8b4b5085a68cccbd5883ba",
            "7c928bd97584499c928090ae581fafd2",
            "af4b9600e9ea46158c6ccb44afcee88d",
            "61844edc71d64f48885e06fee4692281",
            "f19b2bd233794aa08a45b530a2e3acfe",
            "79f0d827b98b43f28b0ac3eda81ab1fe",
            "365f234f3c3d400b9d2d5770996db63c",
            "4cf4472bc8f2473ea175e0e5cb11f952",
            "d534d2dc8baa4940bde4925c65cd4509",
            "9bdbf42fe0e044b4a0267abc3da86f53"
          ]
        },
        "id": "F1SSnQAMD8_Z",
        "outputId": "d0adeadc-f572-49bc-d687-7e561958b612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.93k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00165aaf10ca4e61a424e5960e8783d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.08435759227032555}\n",
            "Test Loss: 7.6610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_adamw_n.load_state_dict(torch.load('/content/drive/MyDrive/Adamw/absolute_positional_encoding/sparsecategoricalcrossentropy/model_metrics_adamw_n.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDkuSWcEyTw8",
        "outputId": "d446c192-4c18-4d68-f0bf-2226a07b7fa5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_adamw_n = nn.NLLLoss(ignore_index=PAD_IDX)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_adamw_n.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          logits = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_adamw = test_and_evaluate(model_adamw_n, test_dataloader, seq2seq_loss_adamw_n, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-emZZlsyhRi",
        "outputId": "aba266fe-b831-4006-dd1b-57680cd76a1d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.1059049926012164}\n",
            "Test Loss: 3.4776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sgd.load_state_dict(torch.load('/content/drive/MyDrive/SGD/absolute_positional_encoding/crossentropyloss/model_sgd_state.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH7duS1FyzMY",
        "outputId": "12782c63-a04b-4b89-9c3b-bad6255f3f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_sgd = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_sgd.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_sgd = test_and_evaluate(model_sgd, test_dataloader, seq2seq_loss_sgd, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBOIQoNmzF84",
        "outputId": "02ccaaa8-fb14-4384-c29d-360b8397fe58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.050421514673167724}\n",
            "Test Loss: 6.8781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sgd_ls.load_state_dict(torch.load('/content/drive/MyDrive/SGD/absolute_positional_encoding/crossentropywithlabelsmoothning/model_sgd_ls_state.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7uVvvaQzZec",
        "outputId": "557a5e2e-c537-4bcc-9cbf-20c924ecd110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_sgd_ls = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_sgd_ls.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_sgd_ls = test_and_evaluate(model_sgd_ls, test_dataloader, seq2seq_loss_sgd_ls, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9r_Uftbz0pL",
        "outputId": "ec555fa0-736f-42b0-d63b-18913c8532a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.04752838603414884}\n",
            "Test Loss: 7.3659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sgd_n.load_state_dict(torch.load('/content/drive/MyDrive/SGD/absolute_positional_encoding/sparsecategoricalcrossentropy/model_sgd_n_state.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3wBIZVY0ERO",
        "outputId": "3fa441a9-3e20-4f70-c36d-8c369511fe0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "import evaluate\n",
        "seq2seq_loss_sgd_n = nn.NLLLoss(ignore_index=PAD_IDX)\n",
        "def remove_repetitions(sentence):\n",
        "    tokens = sentence.split()\n",
        "    previous_token = None\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if token != previous_token:\n",
        "            filtered_tokens.append(token)\n",
        "            previous_token = token\n",
        "    return ' '.join(filtered_tokens)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_sgd_n.to(device)\n",
        "def test_and_evaluate(model, test_dataloader, loss_fn, vocab_en, vocab_fr, num_examples=10):\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    examples_printed = 0\n",
        "    meteor = evaluate.load('meteor')\n",
        "    references = []\n",
        "    candidates = []\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in test_dataloader:\n",
        "          src, tgt = src.to(device), tgt.to(device)\n",
        "          src = src.T\n",
        "          tgt_inp = tgt.T\n",
        "          tgt_input = tgt_inp[:-1, :]\n",
        "          tgt_output = tgt_inp[1:, :]\n",
        "          src_seq_length = src.shape[0]\n",
        "          tgt_seq_length = tgt_input.shape[0]\n",
        "          src_mask = torch.zeros(src_seq_length, src_seq_length).to(device).type(torch.bool)\n",
        "          tgt_mask = model.generate_square_subsequent_mask(tgt_seq_length).to(device)\n",
        "          src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(device)\n",
        "          tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1).to(device)\n",
        "\n",
        "          logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
        "          logits = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "          loss = loss_fn(logits.view(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "          total_test_loss += loss.item()\n",
        "          if examples_printed < num_examples:\n",
        "              predictions = logits.argmax(dim=-1)\n",
        "              for i in range(predictions.size(1)):\n",
        "                  if examples_printed >= num_examples:\n",
        "                      break\n",
        "                  # input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['PAD_IDX'], vocab_en['<BOS>'], vocab_en['<EOS>'])])\n",
        "                  input_sentence = ' '.join([vocab_en.get_itos()[idx] for idx in src[:, i] if idx not in (vocab_en['<pad>'], vocab_en['<bos>'], vocab_en['<eos>'])])\n",
        "                  target_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in tgt[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # predicted_sentence = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  # translated\n",
        "                  predicted_sentence = remove_repetitions(' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])]))\n",
        "                  predicted_sentence_with_repititions = ' '.join([vocab_fr.get_itos()[idx] for idx in predictions[:, i] if idx not in (vocab_fr['<pad>'], vocab_fr['<bos>'], vocab_fr['<eos>'])])\n",
        "                  #print(f'Input: {input_sentence}')\n",
        "                  #print(f'Target: {target_sentence}')\n",
        "                  #print(f'Predicted: {predicted_sentence}')\n",
        "                  #print(f'Predicted with repetitions: {predicted_sentence_with_repititions}')\n",
        "                  #print()\n",
        "                  examples_printed += 1\n",
        "                  references.append([target_sentence])\n",
        "                  candidates.append(predicted_sentence)\n",
        "    meteor_score = meteor.compute(predictions=candidates, references=references)\n",
        "    print(f'Meteor Score: {meteor_score}')\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "    return avg_test_loss\n",
        "test_loss_sgd_ls = test_and_evaluate(model_sgd_n, test_dataloader, seq2seq_loss_sgd_n, vocab_en, vocab_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbII5ZI60WuL",
        "outputId": "7146a537-bac6-4fea-8737-884558fddcf1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteor Score: {'meteor': 0.06805303595540604}\n",
            "Test Loss: 6.9419\n"
          ]
        }
      ]
    }
  ]
}